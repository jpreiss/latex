@book{sutton-barto,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning: An introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  edition   = {second},
  year      = {2018}
}

@unpublished{ajks,
  author    = {Alekh Agarwal and
               Nan Jiang and
               Sham M. Kakade Wen and
               Sun},
  title     = {Reinforcement Learning: Theory and Algorithms},
  note      = {Working draft},
  month     = {January},
  year      = {2022},
  url       = {https://rltheorybook.github.io}
}

@book{lattimore-bandit-algorithms,
  author    = {Tor Lattimore and
               Csaba Szepesv\'ari},
  title     = {Bandit Algorithms},
  year      = {2020},
  publisher = {Cambridge University Press}
}

@book{bertsekas-stochastic-optimal-control,
  author    = {Dimitri P. Bertsekas and
               Steven E. Shreve},
  title     = {Stochastic Optimal Control: The Discrete Time Case},
  series    = {Mathematics in Science and Engineering},
  publisher = {Academic Press},
  year      = {1978}
}

@unpublished{csaba-rltheory-coursenotes,
  author = {Csaba Szepesv\'ari},
  title  = {Lecture notes on Theoretical Foundations of Reinforcement Learning},
  year   = {2024},
  url    = {https://rltheory.github.io/}
}


@incollection{feinberg2011total,
  title={Total expected discounted reward MDPs: existence of optimal policies},
  author={Feinberg, Eugene A},
  booktitle={Wiley Encyclopedia of Operations Research and Management Science},
  year={2011},
  publisher={Wiley Hoboken, NJ, USA}
}

@inproceedings{schulman-trpo,
  author    = {John Schulman and
               Sergey Levine and
               Pieter Abbeel and
               Michael I. Jordan and
               Philipp Moritz},
  title     = {Trust Region Policy Optimization},
  booktitle = {\ICML},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {37},
  pages     = {1889--1897},
  publisher = {JMLR.org},
  year      = {2015}
}

@article{openai-gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {Open{AI} {G}ym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016}
}

@misc{openai-baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{duan-benchmarking-DRL,
  author    = {Yan Duan and
               Xi Chen and
               Rein Houthooft and
               John Schulman and
               Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1604.06778},
  year      = {2016}
}

@inproceedings{todorov-mujoco,
  author    = {Emanuel Todorov and
               Tom Erez and
               Yuval Tassa},
  title     = {{MuJoCo}: {A} physics engine for model-based control},
  booktitle = {\IROS},
  pages     = {5026--5033},
  year      = {2012}
}

@article{zhang-study-on-overfitting,
  author    = {Chiyuan Zhang and
               Oriol Vinyals and
               R{\'{e}}mi Munos and
               Samy Bengio},
  title     = {A Study on Overfitting in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1804.06893},
  year      = {2018}
}

@inproceedings{teh-distral,
  author    = {Yee Whye Teh and
               Victor Bapst and
               Wojciech M. Czarnecki and
               John Quan and
               James Kirkpatrick and
               Raia Hadsell and
               Nicolas Heess and
               Razvan Pascanu},
  title     = {Distral: Robust multitask reinforcement learning},
  booktitle = {\NIPS},
  pages     = {4499--4509},
  year      = {2017}
}

@article{duan-rl2,
  author    = {Yan Duan and
               John Schulman and
               Xi Chen and
               Peter L. Bartlett and
               Ilya Sutskever and
               Pieter Abbeel},
  title     = {{RL}$^2$: Fast Reinforcement Learning via
               Slow Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.02779},
  year      = {2016}
}

@article{OpenAI-dexterous,
  author    = {OpenAI},
  title     = {Learning Dexterous In-Hand Manipulation},
  journal   = {CoRR},
  volume    = {abs/1808.00177},
  year      = {2018}
}

@inproceedings{calandra-inverse-dynamics-contacts-icra15,
  author    = {Roberto Calandra and
               Serena Ivaldi and
               Marc Peter Deisenroth and
               Elmar A. R{\"{u}}ckert and
               Jan Peters},
  title     = {Learning inverse dynamics models with contacts},
  booktitle = {\ICRA},
  pages     = {3186--3191},
  publisher = {{IEEE}},
  year      = {2015}
}

@article{shelhamer-loss-own-reward-arxiv16,
  author    = {Evan Shelhamer and
               Parsa Mahmoudieh and
               Max Argus and
               Trevor Darrell},
  title     = {Loss is its own Reward: Self-Supervision for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1612.07307},
  year      = {2016}
}

@inproceedings{haarnoja-sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  booktitle = {\ICML},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {80},
  pages     = {1856--1865},
  publisher = {JMLR.org},
  year      = {2018}
}

@article{lillicrap-DDPG,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/1509.02971},
  year      = {2015}
}

@article{held-goal-generation,
  author    = {David Held and
               Xinyang Geng and
               Carlos Florensa and
               Pieter Abbeel},
  title     = {Automatic Goal Generation for Reinforcement Learning Agents},
  journal   = {CoRR},
  volume    = {abs/1705.06366},
  year      = {2017}
}

@article{fujimoto-actor-critic-approx-error,
  author    = {Scott Fujimoto and
               Herke van Hoof and
               Dave Meger},
  title     = {Addressing Function Approximation Error in Actor-Critic Methods},
  journal   = {CoRR},
  volume    = {abs/1802.09477},
  year      = {2018}
}

@article{mania-random-search-RL,
  author    = {Horia Mania and
               Aurelia Guy and
               Benjamin Recht},
  title     = {Simple random search provides a competitive approach to reinforcement
               learning},
  journal   = {CoRR},
  volume    = {abs/1803.07055},
  year      = {2018}
}

@inproceedings{hausman-embedding-2018,
  author = {Karol Hausman and
            Jost Tobias Springenberg and
            Ziyu Wang and
            Nicolas Heess and
            Martin Riedmiller},
  title = {Learning an Embedding Space for Transferable Robot Skills},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year = {2018},
}

@inproceedings{Q-learning-nearest-neighbors,
  author    = {Devavrat Shah and
               Qiaomin Xie},
  title     = {Q-learning with Nearest Neighbors},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {3115--3125},
  year      = {2018}
}

@article{finn-gan-IRL-connection,
  author    = {Chelsea Finn and
               Paul F. Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016}
}

@article{bartlett2002estimation,
  title={Estimation and approximation bounds for gradient-based reinforcement learning},
  author={Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Computer and System Sciences},
  volume={64},
  number={1},
  pages={133--150},
  year={2002},
  publisher={Academic Press}
}

@article{greensmith2004variance,
  title={Variance reduction techniques for gradient estimates in reinforcement learning},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  pages={1471--1530},
  year={2004}
}

@inproceedings{lau2012importance,
  title={The importance of variance reduction in policy gradient method},
  author={Lau, Tak Kit and Liu, Yun-hui},
  booktitle={American Control Conference (ACC), 2012},
  pages={1376--1381},
  year={2012},
  organization={IEEE}
}


@misc{mao2018variance,
Author = {Hongzi Mao and Shaileshh Bojja Venkatakrishnan and Malte Schwarzkopf and Mohammad Alizadeh},
Title = {Variance Reduction for Reinforcement Learning in Input-Driven Environments},
Year = {2018},
Eprint = {arXiv:1807.02264},
}

@inproceedings{tokui2017evaluating,
  title={Evaluating the Variance of Likelihood-Ratio Gradient Estimators},
  author={Tokui, Seiya and Sato, Issei},
  booktitle={International Conference on Machine Learning},
  pages={3414--3423},
  year={2017}
}

@article{williams-REINFORCE,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Machine Learning},
  volume    = {8},
  pages     = {229--256},
  year      = {1992}
}

@inproceedings{henderson-deep-rl-that-matters,
  author    = {Peter Henderson and
               Riashat Islam and
               Philip Bachman and
               Joelle Pineau and
               Doina Precup and
               David Meger},
  title     = {Deep Reinforcement Learning That Matters},
  booktitle = {\AAAI},
  pages     = {3207--3214},
  publisher = {{AAAI} Press},
  year      = {2018},
}

@article{schulman-ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@article{duan-benchmarking,
  author    = {Yan Duan and
               Xi Chen and
               Rein Houthooft and
               John Schulman and
               Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1604.06778},
  year      = {2016}
}

@article{levine-rl-inference,
  author    = {Sergey Levine},
  title     = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial
               and Review},
  journal   = {CoRR},
  volume    = {abs/1805.00909},
  year      = {2018}
}

@inproceedings{haarnoja-latent,
  author    = {Tuomas Haarnoja and
               Kristian Hartikainen and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Latent Space Policies for Hierarchical Reinforcement Learning},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {1846--1855},
  publisher = {{PMLR}},
  year      = {2018}
}

@inproceedings{kulkarni-hierarchical,
  author    = {Tejas D. Kulkarni and
               Karthik Narasimhan and
               Ardavan Saeedi and
               Josh Tenenbaum},
  title     = {Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction
               and Intrinsic Motivation},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {3675--3683},
  year      = {2016}
}

@article{sutton-options,
  author    = {Richard S. Sutton and
               Doina Precup and
               Satinder P. Singh},
  title     = {Between MDPs and Semi-MDPs: {A} Framework for Temporal Abstraction
               in Reinforcement Learning},
  journal   = {Artif. Intell.},
  volume    = {112},
  number    = {1-2},
  pages     = {181--211},
  year      = {1999}
}

@InProceedings{schaul-uvfa,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Tom Schaul and Daniel Horgan and Karol Gregor and David Silver},
  booktitle = 	 {\ICML},
  pages = 	 {1312--1320},
  year = 	 {2015},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  publisher = 	 {PMLR},
}

@inproceedings{chen-hardware-conditioned,
  author    = {Tao Chen and
               Adithyavairavan Murali and
               Abhinav Gupta},
  title     = {Hardware Conditioned Policies for Multi-Robot Transfer Learning},
  booktitle = {\NeurIPS},
  pages     = {9355--9366},
  year      = {2018}
}

@article{bharadhwaj-manga,
  author    = {Homanga Bharadhwaj and
               Shoichiro Yamaguchi and
               Shin{-}ichi Maeda},
  title     = {{MANGA:} Method Agnostic Neural-policy Generalization and Adaptation},
  journal   = {CoRR},
  volume    = {abs/1911.08444},
  year      = {2019}
}

@article{peng-sim2real-domrand,
  author    = {Xue Bin Peng and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Sim-to-Real Transfer of Robotic Control with Dynamics Randomization},
  journal   = {CoRR},
  volume    = {abs/1710.06537},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.06537},
  archivePrefix = {arXiv},
  eprint    = {1710.06537},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-06537.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{yu-gradient-surgery,
    title={Gradient Surgery for Multi-Task Learning},
    author={Tianhe Yu and Saurabh Kumar and Abhishek Gupta and Sergey Levine and Karol Hausman and Chelsea Finn},
    year={2020},
    eprint={2001.06782},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{rosenbaum-routing-networks,
  author    = {Clemens Rosenbaum and
               Tim Klinger and
               Matthew Riemer},
  title     = {Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task
               Learning},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=ry8dvM-R-},
  timestamp = {Thu, 25 Jul 2019 14:25:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/RosenbaumKR18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dasilva-parameterized-skills,
    author = {Bruno Castro Da Silva and George Konidaris and Andrew G. Barto},
    title = {Learning parameterized skills},
    booktitle = {Proceedings of International Conference of Machine Learning},
    year = {2012}
}

@inproceedings{deisenroth-multitask-robotics,
  author    = {Marc Peter Deisenroth and
               Peter Englert and
               Jan Peters and
               Dieter Fox},
  title     = {Multi-task policy search for robotics},
  booktitle = {\ICRA},
  pages     = {3876--3881},
  publisher = {{IEEE}},
  year      = {2014}
}

@inproceedings{bou-ammar-multitask-pg,
  author    = {Haitham Bou{-}Ammar and
               Eric Eaton and
               Paul Ruvolo and
               Matthew E. Taylor},
  title     = {Online Multi-Task Learning for Policy Gradient Methods},
  booktitle = {{ICML}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {32},
  pages     = {1206--1214},
  publisher = {JMLR.org},
  year      = {2014}
}

@inproceedings{yu-simreal-biped,
  author    = {Wenhao Yu and
               Visak C. V. Kumar and
               Greg Turk and
               C. Karen Liu},
  title     = {Sim-to-Real Transfer for Biped Locomotion},
  booktitle = {{IROS}},
  pages     = {3503--3510},
  publisher = {{IEEE}},
  year      = {2019}
}

@inproceedings{wang-general-value-approx-neurips20,
  author    = {Ruosong Wang and
               Russ R. Salakhutdinov and
               Lin F. Yang},
  title     = {Reinforcement Learning with General Value Function Approximation:
               Provably Efficient Approach via Bounded Eluder Dimension},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@article{wei-infinite-avg-linear,
  author    = {Chen{-}Yu Wei and
               Mehdi Jafarnia{-}Jahromi and
               Haipeng Luo and
               Rahul Jain},
  title     = {Learning Infinite-horizon Average-reward {MDPs} with Linear Function Approximation},
  journal   = {CoRR},
  volume    = {abs/2007.11849},
  year      = {2020}
}


@InProceedings{wei-infinite-avg-finite,
  title = 	 {Model-free Reinforcement Learning in Infinite-horizon Average-reward {M}arkov Decision Processes},
  author =       {Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
  booktitle = 	 {\ICML},
  pages = 	 {10170--10180},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}


@article{kakade-nonlinear-regret,
  author    = {Sham M. Kakade and
               Akshay Krishnamurthy and
               Kendall Lowrey and
               Motoya Ohnishi and
               Wen Sun},
  title     = {Information Theoretic Regret Bounds for Online Nonlinear Control},
  journal   = {CoRR},
  volume    = {abs/2006.12466},
  year      = {2020}
}


@InProceedings{boffi-regret-adaptive,
  title = 	 {Regret Bounds for Adaptive Nonlinear Control},
  author =       {Boffi, Nicholas M. and Tu, Stephen and Slotine, Jean-Jacques E.},
  booktitle = 	 {\LFOURDC},
  pages = 	 {471--483},
  year = 	 {2021},
  editor = 	 {Jadbabaie, Ali and Lygeros, John and Pappas, George J. and Parrilo, Pablo A. and Recht, Benjamin and Tomlin, Claire J. and Zeilinger, Melanie N.},
  volume = 	 {144},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07 -- 08 June},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v144/boffi21a/boffi21a.pdf},
}

@article{eysenbach-maxent-robust,
  author    = {Benjamin Eysenbach and
               Sergey Levine},
  title     = {Maximum Entropy {RL} (Provably) Solves Some Robust {RL} Problems},
  journal   = {CoRR},
  volume    = {abs/2103.06257},
  year      = {2021}
}


@inproceedings{agarwal-pcpg,
  author = {Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  booktitle = {\NeurIPS},
  pages = {13399--13412},
  title = {{PC-PG}: Policy Cover Directed Exploration for Provable Policy Gradient Learning},
  volume = {33},
  year = {2020},
}

@inproceedings{jin-q-learning-efficient,
  author    = {Chi Jin and
               Zeyuan Allen{-}Zhu and
               S{\'{e}}bastien Bubeck and
               Michael I. Jordan},
  title     = {Is {Q}-Learning Provably Efficient?},
  booktitle = {\NeurIPS},
  pages     = {4868--4878},
  year      = {2018},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/d3b1fb02964aa64e257f9f26a31f72cf-Abstract.html},
}

@article{papadimitriou1987complexity,
  title={The complexity of {Markov} decision processes},
  author={Papadimitriou, Christos H and Tsitsiklis, John N},
  journal={Mathematics of operations research},
  volume={12},
  number={3},
  pages={441--450},
  year={1987},
  publisher={INFORMS}
}

@article{silver-alphazero,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{schrittwieser-muzero,
  title={Mastering {Atari}, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{mnih-dqn,
  title={Playing {Atari} with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={CoRR},
  volume={abs/1312.5602},
  year={2013}
}

@inproceedings{engstrom-implementation-matters-rl,
  author    = {Logan Engstrom and
               Andrew Ilyas and
               Shibani Santurkar and
               Dimitris Tsipras and
               Firdaus Janoos and
               Larry Rudolph and
               Aleksander Madry},
  title     = {Implementation Matters in Deep {RL:} {A} Case Study on {PPO} and {TRPO}},
  booktitle = {\ICLR},
  year      = {2020}
}

@article{andrychowicz2020matters,
  author    = {Marcin Andrychowicz and
               Anton Raichuk and
               Piotr Stanczyk and
               Manu Orsini and
               Sertan Girgin and
               Rapha{\"{e}}l Marinier and
               L{\'{e}}onard Hussenot and
               Matthieu Geist and
               Olivier Pietquin and
               Marcin Michalski and
               Sylvain Gelly and
               Olivier Bachem},
  title     = {What Matters In On-Policy Reinforcement Learning? {A} Large-Scale
               Empirical Study},
  journal   = {CoRR},
  volume    = {abs/2006.05990},
  year      = {2020}
}

@inproceedings{agarwal-statistical-precipice,
 author = {Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
 booktitle = {\NeurIPS},
 pages = {29304--29320},
 title = {Deep Reinforcement Learning at the Edge of the Statistical Precipice},
 url = {https://proceedings.neurips.cc/paper/2021/file/f514cec81cb148559cf475e7426eed5e-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{kalashnikov2018scalable,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {\CORL},
  series    = {Proceedings of Machine Learning Research},
  volume    = {87},
  pages     = {651--673},
  publisher = {{PMLR}},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v87/kalashnikov18a.html},
}

@inproceedings{molchanov2019sim,
  title={Sim-to-(multi)-real: Transfer of low-level robust control policies to multiple quadrotors},
  author={Molchanov, Artem and Chen, Tao and H{\"o}nig, Wolfgang and Preiss, James A and Ayanian, Nora and Sukhatme, Gaurav S},
  booktitle={\IROS},
  pages={59--66},
  year={2019},
  organization={IEEE}
}

@inproceedings{wierstra-recurrent-policy-gradient,
  title={Solving deep memory {POMDP}s with recurrent policy gradients},
  author={Wierstra, Daan and Foerster, Alexander and Peters, Jan and Schmidhuber, Juergen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={697--706},
  year={2007},
  organization={Springer}
}

@inproceedings{peshkin2001learning,
  author    = {Leonid Peshkin and
               Nicolas Meuleau and
               Leslie Pack Kaelbling},
  editor    = {Ivan Bratko and
               Saso Dzeroski},
  title     = {Learning Policies with External Memory},
  booktitle = {\ICML},
  pages     = {307--314},
  publisher = {Morgan Kaufmann},
  year      = {1999},
}

@article{akkaya2019rubiks,
  author    = {OpenAI and
               Ilge Akkaya and
               Marcin Andrychowicz and
               Maciek Chociej and
               Mateusz Litwin and
               Bob McGrew and
               Arthur Petron and
               Alex Paino and
               Matthias Plappert and
               Glenn Powell and
               Raphael Ribas and
               Jonas Schneider and
               Nikolas Tezak and
               Jerry Tworek and
               Peter Welinder and
               Lilian Weng and
               Qiming Yuan and
               Wojciech Zaremba and
               Lei Zhang},
  title     = {Solving {Rubik's} Cube with a Robot Hand},
  journal   = {CoRR},
  volume    = {abs/1910.07113},
  year      = {2019}
}

@article{hwangbo2017quadrotor,
  title={Control of a quadrotor with reinforcement learning},
  author={Hwangbo, Jemin and Sa, Inkyu and Siegwart, Roland and Hutter, Marco},
  journal={\RAL},
  volume={2},
  number={4},
  pages={2096--2103},
  year={2017},
  publisher={IEEE}
}

@InProceedings{chebotar-pilqr,
  title = 	 {Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning},
  author =       {Yevgen Chebotar and Karol Hausman and Marvin Zhang and Gaurav Sukhatme and Stefan Schaal and Sergey Levine},
  booktitle = 	 {\ICML},
  pages = 	 {703--711},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/chebotar17a/chebotar17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/chebotar17a.html},
}

@article{levine-visuomotor,
author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
title = {End-to-End Training of Deep Visuomotor Policies},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {\JMLR},
month = {jan},
pages = {1334–1373},
}

@inproceedings{deisenroth-pilco,
  author    = {Marc Peter Deisenroth and
               Carl Edward Rasmussen},
  editor    = {Lise Getoor and
               Tobias Scheffer},
  title     = {{PILCO:} {A} Model-Based and Data-Efficient Approach to Policy Search},
  booktitle = {\ICML},
  pages     = {465--472},
  publisher = {Omnipress},
  year      = {2011},
  url       = {https://icml.cc/2011/papers/323\_icmlpaper.pdf},
}

@article{raffin-stablebaselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {\JMLR},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@inproceedings{kalashnikov2021corl,
  author    = {Dmitry Kalashnikov and
               Jake Varley and
               Yevgen Chebotar and
               Benjamin Swanson and
               Rico Jonschkowski and
               Chelsea Finn and
               Sergey Levine and
               Karol Hausman},
  title     = {Scaling Up Multi-Task Robotic Reinforcement Learning},
  booktitle = {\CORL},
  series    = {Proceedings of Machine Learning Research},
  volume    = {164},
  pages     = {557--575},
  publisher = {{PMLR}},
  year      = {2021}
}

@inproceedings{perdomo2021neurips,
 author = {Perdomo, Juan and Umenberger, Jack and Simchowitz, Max},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {29274--29286},
 publisher = {Curran Associates, Inc.},
 title = {Stabilizing Dynamical Systems via Policy Gradient Methods},
 url = {https://proceedings.neurips.cc/paper/2021/file/f4f6dce2f3a0f9dada0c2b5b66452017-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{bhandari2019corr,
  author    = {Jalaj Bhandari and
               Daniel Russo},
  title     = {Global Optimality Guarantees For Policy Gradient Methods},
  journal   = {CoRR},
  volume    = {abs/1906.01786},
  year      = {2019}
}

@article{agarwal-optimality-approximation-policygradient,
  author    = {Alekh Agarwal and
               Sham M. Kakade and
               Jason D. Lee and
               Gaurav Mahajan},
  title     = {Optimality and Approximation with Policy Gradient Methods in {Markov}
               Decision Processes},
  journal   = {CoRR},
  volume    = {abs/1908.00261},
  year      = {2019}
}

@InProceedings{fan2020l4dc,
  title = 	 {A Theoretical Analysis of Deep Q-Learning},
  author =       {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
  booktitle = 	 {\LFOURDC},
  year = 	 {2020},
  editor = 	 {Bayen, Alexandre M. and Jadbabaie, Ali and Pappas, George and Parrilo, Pablo A. and Recht, Benjamin and Tomlin, Claire and Zeilinger, Melanie},
  pages     = {486--489},
  url = 	 {https://proceedings.mlr.press/v120/yang20a.html},
}


@InProceedings{xu2020icml,
  title = 	 {A Finite-Time Analysis of {Q}-Learning with Neural Network Function Approximation},
  author =       {Xu, Pan and Gu, Quanquan},
  booktitle = 	 {\ICML},
  pages = 	 {10555--10565},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/xu20c/xu20c.pdf},
  url = 	 {https://proceedings.mlr.press/v119/xu20c.html},
}

@inproceedings{cai2019neurips,
  author    = {Qi Cai and
               Zhuoran Yang and
               Jason D. Lee and
               Zhaoran Wang},
  title     = {Neural Temporal-Difference Learning Converges to Global Optima},
  booktitle = {\NeurIPS},
  pages     = {11312--11322},
  year      = {2019}
}

@inproceedings{wang2020iclr,
  author    = {Lingxiao Wang and
               Qi Cai and
               Zhuoran Yang and
               Zhaoran Wang},
  title     = {Neural Policy Gradient Methods: Global Optimality and Rates of Convergence},
  booktitle = {\ICLR},
  year      = {2020}
}

@inproceedings{liu2019neurips,
  author    = {Boyi Liu and
               Qi Cai and
               Zhuoran Yang and
               Zhaoran Wang},
  title     = {Neural Trust Region/Proximal Policy Optimization Attains Globally Optimal Policy},
  booktitle = {\NeurIPS},
  pages     = {10564--10575},
  year      = {2019}
}

@inproceedings{agazzi2021iclr,
title={Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime},
author={Andrea Agazzi and Jianfeng Lu},
booktitle={\ICLR},
year={2021},
url={https://openreview.net/forum?id=bB2drc7DPuB}
}

@inproceedings{yang2020neurips,
  author    = {Zhuoran Yang and
               Chi Jin and
               Zhaoran Wang and
               Mengdi Wang and
               Michael I. Jordan},
  title     = {Provably Efficient Reinforcement Learning with Kernel and Neural Function
               Approximations},
  booktitle = {\NeurIPS},
  year      = {2020}
}

@InProceedings{song2021icml,
  title = 	 {{PC-MLP}: Model-based Reinforcement Learning with Policy Cover Guided Exploration},
  author =       {Song, Yuda and Sun, Wen},
  booktitle = 	 {\ICML},
  pages = 	 {9801--9811},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/song21b/song21b.pdf},
  url = 	 {https://proceedings.mlr.press/v139/song21b.html},
}


@InProceedings{jin-linear-mdp,
  title = 	 {Provably efficient reinforcement learning with linear function approximation},
  author =       {Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle = 	 {\COLT},
  pages = 	 {2137--2143},
  year = 	 {2020},
  editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v125/jin20a/jin20a.pdf},
  url = 	 {https://proceedings.mlr.press/v125/jin20a.html},
}

@inproceedings{jin2021neurips,
  author    = {Chi Jin and
               Qinghua Liu and
               Sobhan Miryoosefi},
  title     = {Bellman Eluder Dimension: New Rich Classes of {RL} Problems, and Sample-Efficient
               Algorithms},
  booktitle = {\NeurIPS},
  pages     = {13406--13418},
  year      = {2021}
}


@InProceedings{du2021icml,
  title = 	 {Bilinear Classes: A Structural Framework for Provable Generalization in {RL}},
  author =       {Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle = 	 {\ICML},
  pages = 	 {2826--2836},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/du21a/du21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/du21a.html},
}

@article{mania2022jmlr,
  author    = {Horia Mania and
               Michael I. Jordan and
               Benjamin Recht},
  title     = {Active Learning for Nonlinear System Identification with Guarantees},
  journal   = {\JMLR},
  volume    = {23},
  pages     = {32:1--32:30},
  year      = {2022}
}


@InProceedings{feng2021icml,
  title = 	 {Provably Correct Optimization and Exploration with Non-linear Policies},
  author =       {Feng, Fei and Yin, Wotao and Agarwal, Alekh and Yang, Lin},
  booktitle = 	 {\ICML},
  pages = 	 {3263--3273},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/feng21e/feng21e.pdf},
  url = 	 {https://proceedings.mlr.press/v139/feng21e.html},
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@article{laidlaw2023bridging,
  author       = {Cassidy Laidlaw and
                  Stuart Russell and
                  Anca D. Dragan},
  title        = {Bridging {RL} Theory and Practice with the Effective Horizon},
  journal      = {CoRR},
  volume       = {abs/2304.09853},
  year         = {2023}
}

@article{sehnke2010parameter,
  title={Parameter-exploring policy gradients},
  author={Sehnke, Frank and Osendorfer, Christian and R{\"u}ckstie{\ss}, Thomas and Graves, Alex and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={Neural Networks},
  volume={23},
  number={4},
  pages={551--559},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={Pmlr}
}

@article{foster2021statistical,
  author       = {Dylan J. Foster and
                  Sham M. Kakade and
                  Jian Qian and
                  Alexander Rakhlin},
  title        = {The Statistical Complexity of Interactive Decision Making},
  journal      = {CoRR},
  volume       = {abs/2112.13487},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.13487},
  eprinttype    = {arXiv},
  eprint       = {2112.13487},
  timestamp    = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2112-13487.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{zhong2022unified,
  author       = {Han Zhong and
                  Wei Xiong and
                  Sirui Zheng and
                  Liwei Wang and
                  Zhaoran Wang and
                  Zhuoran Yang and
                  Tong Zhang},
  title        = {{GEC:} {A} Unified Framework for Interactive Decision Making in MDP,
                  POMDP, and Beyond},
  journal      = {CoRR},
  volume       = {abs/2211.01962},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.01962},
  doi          = {10.48550/ARXIV.2211.01962},
  eprinttype    = {arXiv},
  eprint       = {2211.01962},
  timestamp    = {Wed, 27 Dec 2023 11:18:10 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-01962.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{zanette2020inherent,
  author       = {Andrea Zanette and
                  Alessandro Lazaric and
                  Mykel J. Kochenderfer and
                  Emma Brunskill},
  title        = {Learning Near Optimal Policies with Low Inherent Bellman Error},
  journal      = {CoRR},
  volume       = {abs/2003.00153},
  year         = {2020},
  url          = {https://arxiv.org/abs/2003.00153},
  eprinttype    = {arXiv},
  eprint       = {2003.00153},
  timestamp    = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2003-00153.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ecoffet2019goexplore,
  author       = {Adrien Ecoffet and
                  Joost Huizinga and
                  Joel Lehman and
                  Kenneth O. Stanley and
                  Jeff Clune},
  title        = {Go-Explore: a New Approach for Hard-Exploration Problems},
  journal      = {CoRR},
  volume       = {abs/1901.10995},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.10995},
  eprinttype    = {arXiv},
  eprint       = {1901.10995},
  timestamp    = {Sun, 03 Feb 2019 14:23:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-10995.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mhammedi2024powerofresets,
  author       = {Zakaria Mhammedi and
                  Dylan J. Foster and
                  Alexander Rakhlin},
  title        = {The Power of Resets in Online Reinforcement Learning},
  booktitle    = {\NeurIPS},
  year         = {2024},
  url          = {http://papers.nips.cc/paper\_files/paper/2024/hash/16f8a0852b31bc9dc791ecf313247a57-Abstract-Conference.html},
  timestamp    = {Wed, 05 Feb 2025 17:21:59 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/MhammediFR24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{azar2017minimax,
  title = 	 {Minimax Regret Bounds for Reinforcement Learning},
  author =       {Mohammad Gheshlaghi Azar and Ian Osband and R{\'e}mi Munos},
  booktitle = 	 {\ICML},
  pages = 	 {263--272},
  year = 	 {2017},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/azar17a/azar17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/azar17a.html},
}

