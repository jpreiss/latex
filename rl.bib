@book{sutton-barto,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  edition   = 2,
  year      = {2018}
}

@unpublished{agarwal-rl-theory,
  author    = {Alekh Agarwal and
               Nan Jiang and
               Sham M. Kakade Wen and
               Sun},
  title     = {Reinforcement Learning: Theory and Algorithms},
  note      = {working draft},
  month     = {January},
  year      = {2022},
  url       = {https://rltheorybook.github.io}
}

@book{bertekas-stochastic-optimal-control,
  author    = {Dimitri P. Bertsekas and
               Steven E. Shreve},
  title     = {Stochastic Optimal Control: The Discrete Time Case},
  series    = {Mathematics in Science and Engineering},
  publisher = {Academic Press},
  year      = {1978}
}

@inproceedings{schulman-trpo,
  author    = {John Schulman and
               Sergey Levine and
               Pieter Abbeel and
               Michael I. Jordan and
               Philipp Moritz},
  title     = {Trust Region Policy Optimization},
  booktitle = {{ICML}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {37},
  pages     = {1889--1897},
  publisher = {JMLR.org},
  year      = {2015}
}

@article{openai-gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {Open{AI} {G}ym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016}
}

@misc{openai-baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{duan-benchmarking-DRL,
  author    = {Yan Duan and
               Xi Chen and
               Rein Houthooft and
               John Schulman and
               Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1604.06778},
  year      = {2016}
}

@inproceedings{todorov-mujoco,
  author    = {Emanuel Todorov and
               Tom Erez and
               Yuval Tassa},
  title     = {MuJoCo: {A} physics engine for model-based control},
  booktitle = {{IROS}},
  pages     = {5026--5033},
  publisher = {{IEEE}},
  year      = {2012}
}

@article{zhang-study-on-overfitting,
  author    = {Chiyuan Zhang and
               Oriol Vinyals and
               R{\'{e}}mi Munos and
               Samy Bengio},
  title     = {A Study on Overfitting in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1804.06893},
  year      = {2018}
}

@inproceedings{teh-distral,
  author    = {Yee Whye Teh and
               Victor Bapst and
               Wojciech M. Czarnecki and
               John Quan and
               James Kirkpatrick and
               Raia Hadsell and
               Nicolas Heess and
               Razvan Pascanu},
  title     = {Distral: Robust multitask reinforcement learning},
  booktitle = {{NIPS}},
  pages     = {4499--4509},
  year      = {2017}
}

@article{duan-rl2,
  author    = {Yan Duan and
               John Schulman and
               Xi Chen and
               Peter L. Bartlett and
               Ilya Sutskever and
               Pieter Abbeel},
  title     = {RL$^2$: Fast Reinforcement Learning via
               Slow Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.02779},
  year      = {2016}
}

@article{OpenAI-dexterous,
  author    = {OpenAI},
  title     = {Learning Dexterous In-Hand Manipulation},
  journal   = {CoRR},
  volume    = {abs/1808.00177},
  year      = {2018}
}

@inproceedings{calandra-inverse-dynamics-contacts-icra15,
  author    = {Roberto Calandra and
               Serena Ivaldi and
               Marc Peter Deisenroth and
               Elmar A. R{\"{u}}ckert and
               Jan Peters},
  title     = {Learning inverse dynamics models with contacts},
  booktitle = {{ICRA}},
  pages     = {3186--3191},
  publisher = {{IEEE}},
  year      = {2015}
}

@article{shelhamer-loss-own-reward-arxiv16,
  author    = {Evan Shelhamer and
               Parsa Mahmoudieh and
               Max Argus and
               Trevor Darrell},
  title     = {Loss is its own Reward: Self-Supervision for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1612.07307},
  year      = {2016}
}

@inproceedings{haarnoja-soft-actor-critic,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  booktitle = {{ICML}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {80},
  pages     = {1856--1865},
  publisher = {JMLR.org},
  year      = {2018}
}

@article{lillicrap-DDPG,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/1509.02971},
  year      = {2015}
}

@article{held-goal-generation,
  author    = {David Held and
               Xinyang Geng and
               Carlos Florensa and
               Pieter Abbeel},
  title     = {Automatic Goal Generation for Reinforcement Learning Agents},
  journal   = {CoRR},
  volume    = {abs/1705.06366},
  year      = {2017}
}

@article{actor-mimic,
  author    = {Emilio Parisotto and
               Lei Jimmy Ba and
               Ruslan Salakhutdinov},
  title     = {Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.06342},
  year      = {2015}
}

@article{fujimoto-actor-critic-approx-error,
  author    = {Scott Fujimoto and
               Herke van Hoof and
               Dave Meger},
  title     = {Addressing Function Approximation Error in Actor-Critic Methods},
  journal   = {CoRR},
  volume    = {abs/1802.09477},
  year      = {2018}
}

@article{mania-random-search-RL,
  author    = {Horia Mania and
               Aurelia Guy and
               Benjamin Recht},
  title     = {Simple random search provides a competitive approach to reinforcement
               learning},
  journal   = {CoRR},
  volume    = {abs/1803.07055},
  year      = {2018}
}

@inproceedings{hausman-embedding-2018,
  author = {Karol Hausman and
            Jost Tobias Springenberg and
            Ziyu Wang and
            Nicolas Heess and
            Martin Riedmiller},
  title = {Learning an Embedding Space for Transferable Robot Skills},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year = {2018},
}

@inproceedings{Q-learning-nearest-neighbors,
  author    = {Devavrat Shah and
               Qiaomin Xie},
  title     = {Q-learning with Nearest Neighbors},
  booktitle = {NeurIPS},
  pages     = {3115--3125},
  year      = {2018}
}

@article{finn-gan-IRL-connection,
  author    = {Chelsea Finn and
               Paul F. Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016}
}

@article{bartlett2002estimation,
  title={Estimation and approximation bounds for gradient-based reinforcement learning},
  author={Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Computer and System Sciences},
  volume={64},
  number={1},
  pages={133--150},
  year={2002},
  publisher={Academic Press}
}

@article{greensmith2004variance,
  title={Variance reduction techniques for gradient estimates in reinforcement learning},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Nov},
  pages={1471--1530},
  year={2004}
}

@inproceedings{lau2012importance,
  title={The importance of variance reduction in policy gradient method},
  author={Lau, Tak Kit and Liu, Yun-hui},
  booktitle={American Control Conference (ACC), 2012},
  pages={1376--1381},
  year={2012},
  organization={IEEE}
}


@misc{mao2018variance,
Author = {Hongzi Mao and Shaileshh Bojja Venkatakrishnan and Malte Schwarzkopf and Mohammad Alizadeh},
Title = {Variance Reduction for Reinforcement Learning in Input-Driven Environments},
Year = {2018},
Eprint = {arXiv:1807.02264},
}

@inproceedings{tokui2017evaluating,
  title={Evaluating the Variance of Likelihood-Ratio Gradient Estimators},
  author={Tokui, Seiya and Sato, Issei},
  booktitle={International Conference on Machine Learning},
  pages={3414--3423},
  year={2017}
}

@article{williams-REINFORCE,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Machine Learning},
  volume    = {8},
  pages     = {229--256},
  year      = {1992}
}

@inproceedings{henderson-deep-rl-that-matters,
  author    = {Peter Henderson and
               Riashat Islam and
               Philip Bachman and
               Joelle Pineau and
               Doina Precup and
               David Meger},
  title     = {Deep Reinforcement Learning That Matters},
  booktitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  pages     = {3207--3214},
  publisher = {{AAAI} Press},
  year      = {2018},
}

@article{schulman-ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@article{duan-benchmarking,
  author    = {Yan Duan and
               Xi Chen and
               Rein Houthooft and
               John Schulman and
               Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1604.06778},
  year      = {2016}
}

@article{levine-rl-inference,
  author    = {Sergey Levine},
  title     = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial
               and Review},
  journal   = {CoRR},
  volume    = {abs/1805.00909},
  year      = {2018}
}

@inproceedings{haarnoja-latent,
  author    = {Tuomas Haarnoja and
               Kristian Hartikainen and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Latent Space Policies for Hierarchical Reinforcement Learning},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {1846--1855},
  publisher = {{PMLR}},
  year      = {2018}
}

@inproceedings{kulkarni-hierarchical,
  author    = {Tejas D. Kulkarni and
               Karthik Narasimhan and
               Ardavan Saeedi and
               Josh Tenenbaum},
  title     = {Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction
               and Intrinsic Motivation},
  booktitle = {{NIPS}},
  pages     = {3675--3683},
  year      = {2016}
}

@article{sutton-options,
  author    = {Richard S. Sutton and
               Doina Precup and
               Satinder P. Singh},
  title     = {Between MDPs and Semi-MDPs: {A} Framework for Temporal Abstraction
               in Reinforcement Learning},
  journal   = {Artif. Intell.},
  volume    = {112},
  number    = {1-2},
  pages     = {181--211},
  year      = {1999}
}

@InProceedings{schaul-universal-value,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Tom Schaul and Daniel Horgan and Karol Gregor and David Silver},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  publisher = 	 {PMLR},
}

@inproceedings{chen-hardware-conditioned,
  author    = {Tao Chen and
               Adithyavairavan Murali and
               Abhinav Gupta},
  title     = {Hardware Conditioned Policies for Multi-Robot Transfer Learning},
  booktitle = {NeurIPS},
  pages     = {9355--9366},
  year      = {2018}
}

@article{bharadhwaj-manga,
  author    = {Homanga Bharadhwaj and
               Shoichiro Yamaguchi and
               Shin{-}ichi Maeda},
  title     = {{MANGA:} Method Agnostic Neural-policy Generalization and Adaptation},
  journal   = {CoRR},
  volume    = {abs/1911.08444},
  year      = {2019}
}

@article{peng-sim2real-domrand,
  author    = {Xue Bin Peng and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Sim-to-Real Transfer of Robotic Control with Dynamics Randomization},
  journal   = {CoRR},
  volume    = {abs/1710.06537},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.06537},
  archivePrefix = {arXiv},
  eprint    = {1710.06537},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-06537.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{yu-gradient-surgery,
    title={Gradient Surgery for Multi-Task Learning},
    author={Tianhe Yu and Saurabh Kumar and Abhishek Gupta and Sergey Levine and Karol Hausman and Chelsea Finn},
    year={2020},
    eprint={2001.06782},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{rosenbaum-routing-networks,
  author    = {Clemens Rosenbaum and
               Tim Klinger and
               Matthew Riemer},
  title     = {Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task
               Learning},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=ry8dvM-R-},
  timestamp = {Thu, 25 Jul 2019 14:25:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/RosenbaumKR18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dasilva-parameterized-skills,
    author = {Bruno Castro Da Silva and George Konidaris and Andrew G. Barto},
    title = {Learning parameterized skills},
    booktitle = {Proceedings of International Conference of Machine Learning},
    year = {2012}
}

@inproceedings{deisenroth-multitask-robotics,
  author    = {Marc Peter Deisenroth and
               Peter Englert and
               Jan Peters and
               Dieter Fox},
  title     = {Multi-task policy search for robotics},
  booktitle = {{ICRA}},
  pages     = {3876--3881},
  publisher = {{IEEE}},
  year      = {2014}
}

@inproceedings{bou-ammar-multitask-pg,
  author    = {Haitham Bou{-}Ammar and
               Eric Eaton and
               Paul Ruvolo and
               Matthew E. Taylor},
  title     = {Online Multi-Task Learning for Policy Gradient Methods},
  booktitle = {{ICML}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {32},
  pages     = {1206--1214},
  publisher = {JMLR.org},
  year      = {2014}
}

@inproceedings{yu-simreal-biped,
  author    = {Wenhao Yu and
               Visak C. V. Kumar and
               Greg Turk and
               C. Karen Liu},
  title     = {Sim-to-Real Transfer for Biped Locomotion},
  booktitle = {{IROS}},
  pages     = {3503--3510},
  publisher = {{IEEE}},
  year      = {2019}
}

@inproceedings{wang-general-value-approx-neurips20,
  author    = {Ruosong Wang and
               Russ R. Salakhutdinov and
               Lin F. Yang},
  title     = {Reinforcement Learning with General Value Function Approximation:
               Provably Efficient Approach via Bounded Eluder Dimension},
  booktitle = {NeurIPS},
  year      = {2020}
}

@article{wei-infinite-avg-linear,
  author    = {Chen{-}Yu Wei and
               Mehdi Jafarnia{-}Jahromi and
               Haipeng Luo and
               Rahul Jain},
  title     = {Learning Infinite-horizon Average-reward MDPs with Linear Function
               Approximation},
  journal   = {CoRR},
  volume    = {abs/2007.11849},
  year      = {2020}
}

@article{kakade-nonlinear-regret,
  author    = {Sham M. Kakade and
               Akshay Krishnamurthy and
               Kendall Lowrey and
               Motoya Ohnishi and
               Wen Sun},
  title     = {Information Theoretic Regret Bounds for Online Nonlinear Control},
  journal   = {CoRR},
  volume    = {abs/2006.12466},
  year      = {2020}
}


@InProceedings{boffi-regret-adaptive,
  title = 	 {Regret Bounds for Adaptive Nonlinear Control},
  author =       {Boffi, Nicholas M. and Tu, Stephen and Slotine, Jean-Jacques E.},
  booktitle = 	 {Proceedings of the 3rd Conference on Learning for Dynamics and Control},
  pages = 	 {471--483},
  year = 	 {2021},
  editor = 	 {Jadbabaie, Ali and Lygeros, John and Pappas, George J. and A.&nbsp;Parrilo, Pablo and Recht, Benjamin and Tomlin, Claire J. and Zeilinger, Melanie N.},
  volume = 	 {144},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07 -- 08 June},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v144/boffi21a/boffi21a.pdf},
}

@article{eysenbach-maxent-robust,
  author    = {Benjamin Eysenbach and
               Sergey Levine},
  title     = {Maximum Entropy {RL} (Provably) Solves Some Robust {RL} Problems},
  journal   = {CoRR},
  volume    = {abs/2103.06257},
  year      = {2021}
}


@inproceedings{agarwal-pcpg,
  author = {Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {13399--13412},
  title = {PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient Learning},
  volume = {33},
  year = {2020},
}

